{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "\n",
    "N = 300\n",
    "x, t = datasets.make_moons(N, noise=0.3)\n",
    "t = t.reshape(N, 1)\n",
    "\n",
    "x_train, x_test, t_train, t_test = \\\n",
    "    train_test_split(x, t, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24/24 [==============================] - 1s 2ms/step - loss: 0.8587 - accuracy: 0.4667\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.7502 - accuracy: 0.2750\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.7195 - accuracy: 0.3375\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.7005 - accuracy: 0.5167\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6823 - accuracy: 0.5167\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6643 - accuracy: 0.5667\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6453 - accuracy: 0.6292\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6230 - accuracy: 0.8083\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.6017 - accuracy: 0.7917\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5785 - accuracy: 0.7958\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5574 - accuracy: 0.8083\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.8042\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.8042\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.4996 - accuracy: 0.8042\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.4847 - accuracy: 0.8042\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.4706 - accuracy: 0.8000\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.8000\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.8042\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.8208\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.8250\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.8250\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.8250\n",
      "Epoch 23/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.8333\n",
      "Epoch 24/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.4075 - accuracy: 0.8250\n",
      "Epoch 25/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.4013 - accuracy: 0.8292\n",
      "Epoch 26/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3979 - accuracy: 0.8333\n",
      "Epoch 27/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3940 - accuracy: 0.8333\n",
      "Epoch 28/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3910 - accuracy: 0.8417\n",
      "Epoch 29/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.3879 - accuracy: 0.8417\n",
      "Epoch 30/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3854 - accuracy: 0.8458\n",
      "Epoch 31/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3825 - accuracy: 0.8417\n",
      "Epoch 32/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3802 - accuracy: 0.8500\n",
      "Epoch 33/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.3784 - accuracy: 0.8458\n",
      "Epoch 34/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.3773 - accuracy: 0.8500\n",
      "Epoch 35/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.3752 - accuracy: 0.8500\n",
      "Epoch 36/100\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3738 - accuracy: 0.8583\n",
      "Epoch 37/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.3724 - accuracy: 0.8500\n",
      "Epoch 38/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3711 - accuracy: 0.8458\n",
      "Epoch 39/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.3702 - accuracy: 0.8417\n",
      "Epoch 40/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3694 - accuracy: 0.8542\n",
      "Epoch 41/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3689 - accuracy: 0.8458\n",
      "Epoch 42/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.3673 - accuracy: 0.8458\n",
      "Epoch 43/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.3661 - accuracy: 0.8500\n",
      "Epoch 44/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.3664 - accuracy: 0.8542\n",
      "Epoch 45/100\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3650 - accuracy: 0.8500\n",
      "Epoch 46/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.3656 - accuracy: 0.8542\n",
      "Epoch 47/100\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.3642 - accuracy: 0.8542\n",
      "Epoch 48/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.3647 - accuracy: 0.8542\n",
      "Epoch 49/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.3633 - accuracy: 0.8500\n",
      "Epoch 50/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.3639 - accuracy: 0.8583\n",
      "Epoch 51/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3624 - accuracy: 0.8542\n",
      "Epoch 52/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3638 - accuracy: 0.8583\n",
      "Epoch 53/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3621 - accuracy: 0.8458\n",
      "Epoch 54/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3619 - accuracy: 0.8542\n",
      "Epoch 55/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3619 - accuracy: 0.8542\n",
      "Epoch 56/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3620 - accuracy: 0.8542\n",
      "Epoch 57/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3611 - accuracy: 0.8583\n",
      "Epoch 58/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3607 - accuracy: 0.8500\n",
      "Epoch 59/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3621 - accuracy: 0.8583\n",
      "Epoch 60/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3615 - accuracy: 0.8542\n",
      "Epoch 61/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.8542\n",
      "Epoch 62/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3619 - accuracy: 0.8542\n",
      "Epoch 63/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3607 - accuracy: 0.8500\n",
      "Epoch 64/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3613 - accuracy: 0.8500\n",
      "Epoch 65/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3605 - accuracy: 0.8542\n",
      "Epoch 66/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3608 - accuracy: 0.8542\n",
      "Epoch 67/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3611 - accuracy: 0.8500\n",
      "Epoch 68/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3614 - accuracy: 0.8542\n",
      "Epoch 69/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3604 - accuracy: 0.8542\n",
      "Epoch 70/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3598 - accuracy: 0.8542\n",
      "Epoch 71/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3608 - accuracy: 0.8542\n",
      "Epoch 72/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3599 - accuracy: 0.8542\n",
      "Epoch 73/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3612 - accuracy: 0.8542\n",
      "Epoch 74/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8542\n",
      "Epoch 75/100\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 0.3614 - accuracy: 0.8542\n",
      "Epoch 76/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3605 - accuracy: 0.8583\n",
      "Epoch 77/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3600 - accuracy: 0.8542\n",
      "Epoch 78/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8542\n",
      "Epoch 79/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3601 - accuracy: 0.8500\n",
      "Epoch 80/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3602 - accuracy: 0.8583\n",
      "Epoch 81/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3600 - accuracy: 0.8542\n",
      "Epoch 82/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3603 - accuracy: 0.8542\n",
      "Epoch 83/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8500\n",
      "Epoch 84/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3601 - accuracy: 0.8542\n",
      "Epoch 85/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3603 - accuracy: 0.8625\n",
      "Epoch 86/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8583\n",
      "Epoch 87/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3596 - accuracy: 0.8542\n",
      "Epoch 88/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3594 - accuracy: 0.8500\n",
      "Epoch 89/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3600 - accuracy: 0.8542\n",
      "Epoch 90/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3601 - accuracy: 0.8542\n",
      "Epoch 91/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3596 - accuracy: 0.8542\n",
      "Epoch 92/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3599 - accuracy: 0.8542\n",
      "Epoch 93/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3609 - accuracy: 0.8542\n",
      "Epoch 94/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8500\n",
      "Epoch 95/100\n",
      "24/24 [==============================] - 0s 1ms/step - loss: 0.3598 - accuracy: 0.8583\n",
      "Epoch 96/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8542\n",
      "Epoch 97/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3596 - accuracy: 0.8500\n",
      "Epoch 98/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.8542\n",
      "Epoch 99/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3598 - accuracy: 0.8625\n",
      "Epoch 100/100\n",
      "24/24 [==============================] - 0s 2ms/step - loss: 0.3605 - accuracy: 0.8500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a8a80d0460>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = optimizers.SGD(learning_rate=0.1)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, t_train,\n",
    "            epochs=100, batch_size=10,\n",
    "            verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.43351447582244873 , test_acc: 0.800000011920929\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test, t_test, verbose=0)\n",
    "print(\"test_loss:\", loss, \", test_acc:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from keras.models import Model\n",
    "from keras import losses\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(Model):\n",
    "    def __init__(self, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.l1 = Dense(hidden_dim, activation='sigmoid')\n",
    "        self.l2 = Dense(output_dim, activation='sigmoid')\n",
    "\n",
    "    def call(self, x):\n",
    "        h = self.l1(x)\n",
    "        y = self.l2(h)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 17.0\n",
      "epoch: 2, loss: 16.4\n",
      "epoch: 3, loss: 16.0\n",
      "epoch: 4, loss: 15.7\n",
      "epoch: 5, loss: 15.4\n",
      "epoch: 6, loss: 15.0\n",
      "epoch: 7, loss: 14.6\n",
      "epoch: 8, loss: 14.3\n",
      "epoch: 9, loss: 13.9\n",
      "epoch: 10, loss: 13.4\n",
      "epoch: 11, loss: 13.1\n",
      "epoch: 12, loss: 12.7\n",
      "epoch: 13, loss: 12.3\n",
      "epoch: 14, loss: 12.0\n",
      "epoch: 15, loss: 11.7\n",
      "epoch: 16, loss: 11.4\n",
      "epoch: 17, loss: 11.1\n",
      "epoch: 18, loss: 10.9\n",
      "epoch: 19, loss: 10.7\n",
      "epoch: 20, loss: 10.5\n",
      "epoch: 21, loss: 10.3\n",
      "epoch: 22, loss: 10.1\n",
      "epoch: 23, loss: 10.0\n",
      "epoch: 24, loss: 9.87\n",
      "epoch: 25, loss: 9.76\n",
      "epoch: 26, loss: 9.66\n",
      "epoch: 27, loss: 9.54\n",
      "epoch: 28, loss: 9.47\n",
      "epoch: 29, loss: 9.39\n",
      "epoch: 30, loss: 9.32\n",
      "epoch: 31, loss: 9.25\n",
      "epoch: 32, loss: 9.2\n",
      "epoch: 33, loss: 9.17\n",
      "epoch: 34, loss: 9.09\n",
      "epoch: 35, loss: 9.06\n",
      "epoch: 36, loss: 9.01\n",
      "epoch: 37, loss: 9.0\n",
      "epoch: 38, loss: 8.95\n",
      "epoch: 39, loss: 8.93\n",
      "epoch: 40, loss: 8.89\n",
      "epoch: 41, loss: 8.87\n",
      "epoch: 42, loss: 8.85\n",
      "epoch: 43, loss: 8.84\n",
      "epoch: 44, loss: 8.82\n",
      "epoch: 45, loss: 8.78\n",
      "epoch: 46, loss: 8.78\n",
      "epoch: 47, loss: 8.78\n",
      "epoch: 48, loss: 8.76\n",
      "epoch: 49, loss: 8.76\n",
      "epoch: 50, loss: 8.73\n",
      "epoch: 51, loss: 8.73\n",
      "epoch: 52, loss: 8.75\n",
      "epoch: 53, loss: 8.72\n",
      "epoch: 54, loss: 8.73\n",
      "epoch: 55, loss: 8.72\n",
      "epoch: 56, loss: 8.68\n",
      "epoch: 57, loss: 8.69\n",
      "epoch: 58, loss: 8.69\n",
      "epoch: 59, loss: 8.69\n",
      "epoch: 60, loss: 8.71\n",
      "epoch: 61, loss: 8.68\n",
      "epoch: 62, loss: 8.7\n",
      "epoch: 63, loss: 8.68\n",
      "epoch: 64, loss: 8.66\n",
      "epoch: 65, loss: 8.67\n",
      "epoch: 66, loss: 8.68\n",
      "epoch: 67, loss: 8.66\n",
      "epoch: 68, loss: 8.67\n",
      "epoch: 69, loss: 8.65\n",
      "epoch: 70, loss: 8.68\n",
      "epoch: 71, loss: 8.66\n",
      "epoch: 72, loss: 8.65\n",
      "epoch: 73, loss: 8.68\n",
      "epoch: 74, loss: 8.67\n",
      "epoch: 75, loss: 8.68\n",
      "epoch: 76, loss: 8.65\n",
      "epoch: 77, loss: 8.67\n",
      "epoch: 78, loss: 8.64\n",
      "epoch: 79, loss: 8.65\n",
      "epoch: 80, loss: 8.66\n",
      "epoch: 81, loss: 8.66\n",
      "epoch: 82, loss: 8.66\n",
      "epoch: 83, loss: 8.66\n",
      "epoch: 84, loss: 8.66\n",
      "epoch: 85, loss: 8.68\n",
      "epoch: 86, loss: 8.66\n",
      "epoch: 87, loss: 8.64\n",
      "epoch: 88, loss: 8.67\n",
      "epoch: 89, loss: 8.66\n",
      "epoch: 90, loss: 8.65\n",
      "epoch: 91, loss: 8.66\n",
      "epoch: 92, loss: 8.65\n",
      "epoch: 93, loss: 8.66\n",
      "epoch: 94, loss: 8.66\n",
      "epoch: 95, loss: 8.65\n",
      "epoch: 96, loss: 8.65\n",
      "epoch: 97, loss: 8.66\n",
      "epoch: 98, loss: 8.65\n",
      "epoch: 99, loss: 8.66\n",
      "epoch: 100, loss: 8.64\n"
     ]
    }
   ],
   "source": [
    "model = MLP(3, 1)\n",
    "\n",
    "criterion = losses.BinaryCrossentropy()\n",
    "optimizer = optimizers.SGD(learning_rate=0.1)\n",
    "\n",
    "def compute_loss(t, y):\n",
    "    return criterion(t, y)\n",
    "\n",
    "def train_step(x, t):\n",
    "    with tf.GradientTape() as tape:\n",
    "        preds = model(x)\n",
    "        loss = compute_loss(t, preds)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 10\n",
    "n_batches = x_train.shape[0] // batch_size\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.\n",
    "    x_, t_ = shuffle(x_train, t_train)\n",
    "\n",
    "    for batch in range(n_batches):\n",
    "        start = batch * batch_size\n",
    "        end = start + batch_size\n",
    "        loss = train_step(x_[start:end], t_[start:end])\n",
    "        train_loss += loss.numpy()\n",
    "\n",
    "    print('epoch: {}, loss: {:.3}'.format(\n",
    "        epoch+1,\n",
    "        train_loss\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.432, test_acc: 0.800\n"
     ]
    }
   ],
   "source": [
    "test_loss = metrics.Mean()\n",
    "test_acc = metrics.BinaryAccuracy()\n",
    "\n",
    "def test_step(x, t):\n",
    "    preds = model(x)\n",
    "    loss = compute_loss(t, preds)\n",
    "    test_loss(loss)\n",
    "    test_acc(t, preds)\n",
    "\n",
    "    return loss\n",
    "\n",
    "test_step(x_test, t_test)\n",
    "\n",
    "print('test_loss: {:.3f}, test_acc: {:.3f}'.format(\n",
    "    test_loss.result(),\n",
    "    test_acc.result()\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    '''\n",
    "    多層パーセプトロン\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.a1 = nn.Sigmoid()\n",
    "        self.l2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.a2 = nn.Sigmoid()\n",
    "\n",
    "        self.layers = [self.l1, self.a1, self.l2, self.a2]\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "'''\n",
    "1. データの準備\n",
    "'''\n",
    "N = 300\n",
    "x, t = datasets.make_moons(N, noise=0.3)\n",
    "t = t.reshape(N, 1)\n",
    "\n",
    "x_train, x_test, t_train, t_test = \\\n",
    "    train_test_split(x, t, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare model\n",
    "model = MLP(2, 3, 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 17.1\n",
      "epoch: 2, loss: 16.8\n",
      "epoch: 3, loss: 16.6\n",
      "epoch: 4, loss: 16.4\n",
      "epoch: 5, loss: 16.1\n",
      "epoch: 6, loss: 15.9\n",
      "epoch: 7, loss: 15.6\n",
      "epoch: 8, loss: 15.3\n",
      "epoch: 9, loss: 14.9\n",
      "epoch: 10, loss: 14.5\n",
      "epoch: 11, loss: 14.1\n",
      "epoch: 12, loss: 13.7\n",
      "epoch: 13, loss: 13.3\n",
      "epoch: 14, loss: 12.9\n",
      "epoch: 15, loss: 12.5\n",
      "epoch: 16, loss: 12.2\n",
      "epoch: 17, loss: 11.8\n",
      "epoch: 18, loss: 11.6\n",
      "epoch: 19, loss: 11.3\n",
      "epoch: 20, loss: 11.1\n",
      "epoch: 21, loss: 10.9\n",
      "epoch: 22, loss: 10.8\n",
      "epoch: 23, loss: 10.6\n",
      "epoch: 24, loss: 10.5\n",
      "epoch: 25, loss: 10.4\n",
      "epoch: 26, loss: 10.3\n",
      "epoch: 27, loss: 10.2\n",
      "epoch: 28, loss: 10.1\n",
      "epoch: 29, loss: 10.1\n",
      "epoch: 30, loss: 10.0\n",
      "epoch: 31, loss: 9.96\n",
      "epoch: 32, loss: 9.92\n",
      "epoch: 33, loss: 9.86\n",
      "epoch: 34, loss: 9.82\n",
      "epoch: 35, loss: 9.79\n",
      "epoch: 36, loss: 9.75\n",
      "epoch: 37, loss: 9.73\n",
      "epoch: 38, loss: 9.71\n",
      "epoch: 39, loss: 9.68\n",
      "epoch: 40, loss: 9.64\n",
      "epoch: 41, loss: 9.63\n",
      "epoch: 42, loss: 9.61\n",
      "epoch: 43, loss: 9.6\n",
      "epoch: 44, loss: 9.56\n",
      "epoch: 45, loss: 9.55\n",
      "epoch: 46, loss: 9.57\n",
      "epoch: 47, loss: 9.54\n",
      "epoch: 48, loss: 9.51\n",
      "epoch: 49, loss: 9.51\n",
      "epoch: 50, loss: 9.5\n",
      "epoch: 51, loss: 9.51\n",
      "epoch: 52, loss: 9.5\n",
      "epoch: 53, loss: 9.48\n",
      "epoch: 54, loss: 9.48\n",
      "epoch: 55, loss: 9.48\n",
      "epoch: 56, loss: 9.45\n",
      "epoch: 57, loss: 9.47\n",
      "epoch: 58, loss: 9.49\n",
      "epoch: 59, loss: 9.44\n",
      "epoch: 60, loss: 9.44\n",
      "epoch: 61, loss: 9.44\n",
      "epoch: 62, loss: 9.44\n",
      "epoch: 63, loss: 9.44\n",
      "epoch: 64, loss: 9.42\n",
      "epoch: 65, loss: 9.44\n",
      "epoch: 66, loss: 9.42\n",
      "epoch: 67, loss: 9.4\n",
      "epoch: 68, loss: 9.43\n",
      "epoch: 69, loss: 9.41\n",
      "epoch: 70, loss: 9.43\n",
      "epoch: 71, loss: 9.42\n",
      "epoch: 72, loss: 9.4\n",
      "epoch: 73, loss: 9.4\n",
      "epoch: 74, loss: 9.4\n",
      "epoch: 75, loss: 9.4\n",
      "epoch: 76, loss: 9.42\n",
      "epoch: 77, loss: 9.41\n",
      "epoch: 78, loss: 9.37\n",
      "epoch: 79, loss: 9.4\n",
      "epoch: 80, loss: 9.41\n",
      "epoch: 81, loss: 9.41\n",
      "epoch: 82, loss: 9.39\n",
      "epoch: 83, loss: 9.38\n",
      "epoch: 84, loss: 9.38\n",
      "epoch: 85, loss: 9.37\n",
      "epoch: 86, loss: 9.36\n",
      "epoch: 87, loss: 9.37\n",
      "epoch: 88, loss: 9.38\n",
      "epoch: 89, loss: 9.38\n",
      "epoch: 90, loss: 9.39\n",
      "epoch: 91, loss: 9.38\n",
      "epoch: 92, loss: 9.37\n",
      "epoch: 93, loss: 9.37\n",
      "epoch: 94, loss: 9.38\n",
      "epoch: 95, loss: 9.37\n",
      "epoch: 96, loss: 9.36\n",
      "epoch: 97, loss: 9.37\n",
      "epoch: 98, loss: 9.37\n",
      "epoch: 99, loss: 9.37\n",
      "epoch: 100, loss: 9.36\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optimizers.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "def compute_loss(t, y):\n",
    "    return criterion(y, t)\n",
    "\n",
    "def train_step(x, t):\n",
    "    model.train()\n",
    "    preds = model(x)\n",
    "    loss = compute_loss(t, preds)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 10\n",
    "n_batches = x_train.shape[0] // batch_size\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.\n",
    "    x_, t_ = shuffle(x_train, t_train)\n",
    "    x_ = torch.Tensor(x_).to(device)\n",
    "    t_ = torch.Tensor(t_).to(device)\n",
    "\n",
    "    for n_batch in range(n_batches):\n",
    "        start = n_batch * batch_size\n",
    "        end = start + batch_size\n",
    "        loss = train_step(x_[start:end], t_[start:end])\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    print('epoch: {}, loss: {:.3}'.format(\n",
    "        epoch+1,\n",
    "        train_loss\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.302, test_acc: 0.867\n"
     ]
    }
   ],
   "source": [
    "def test_step(x, t):\n",
    "    x = torch.Tensor(x).to(device)\n",
    "    t = torch.Tensor(t).to(device)\n",
    "    model.eval()\n",
    "    preds = model(x)\n",
    "    loss = compute_loss(t, preds)\n",
    "\n",
    "    return loss, preds\n",
    "\n",
    "loss, preds = test_step(x_test, t_test)\n",
    "test_loss = loss.item()\n",
    "preds = preds.data.cpu().numpy() > 0.5\n",
    "test_acc = accuracy_score(t_test, preds)\n",
    "\n",
    "print('test_loss: {:.3f}, test_acc: {:.3f}'.format(\n",
    "    test_loss,\n",
    "    test_acc\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('dl-tf-ptvenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "db57a9e83bb1ac205d6811bc29cda304eb81c335675697ff0a5eeb5067f7012c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
